How Data Analytics and AI are used to halt the COVID-19 Pandemic?

Efficient Supply Chain Assessment: Overcoming Technical Hurdles for Web Application Development
Streamlined Integration: Interactive Brokers API with Python for Desktop Trading Application
Efficient Data Integration and User-Friendly Interface Development: Navigating Challenges in Web Application Deployment
Effective Management of Social Media Data Extraction: Strategies for Authentication, Security, and Reliability
AI Bot Audio to audio
Methodology for ETL Discovery Tool using LLMA, OpenAI, Langchain
Methodology for database discovery tool using openai, LLMA, Langchain
Chatbot using VoiceFlow
Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.
Rising IT Cities and Their Impact on the Economy, Environment, Infrastructure, and City Life in Future
Internet Demand’s Evolution, Communication Impact, and 2035’s Alternative Pathways
Rise of Cybercrime and its Effect in upcoming Future
AI/ML and Predictive Modeling
Solution for Contact Centre Problems
How to Setup Custom Domain for Google App Engine Application?
Code Review Checklist
Even though COVID-19 has not yet halted and we are facing the nth wave of the coronavirus outbreak across several countries, most notably the US, India, and Brazil. It is a fact that Data Analytics and AI are the big guns of our artillery in this fight against the COVID-19 pandemic. It has helped us in several stages of this outbreak, like the detection of its first outbreak, vaccine development and manufacturing contact tracing, and future hotspot detection. Some of these interesting applications are discussed in this article.
A lesser-known fact is that the COVID-19 outbreak was first detected in Toronto, Canada, nearly 7,230 miles away from the first outbreak, nine days before the WHO issued its warning. It was with the help of Big Data Analytics and AI, more specifically Deep Learnings (DL, a subset of Machine Learning) application in Natural Language Processing (NLP) to analyze text inputs that traced the surge of pneumonia cases in the Wuhan province of China. The specialty of DL algorithms is that they mimic the brain cells called neurons and can identify patterns in Big Data. This DL-backed software is used as inputs, reports from public health organizations, global airline ticketing data, etc. These were used to flag unusual surges and potential spreads of infectious diseases.
The next application of Big Data Analytics and AI was in the Research and Development of drugs to halt COVID-19. AI was used to analyze the protein structure of the virus, findings that were significant in the progress of vaccine development. In preliminary studies, it was found that it does not mutate as fast as other viruses such as HIV, which means that a prophylactic vaccine is a better way to proceed rather than a therapy. But there is also some evidence supporting the fact that when we find any kind of cure for it, there is a chance of the virus mutating, which is what happened and major mutations have been found in the UK, Brazil, and South Africa. AI also assisted scientists in rapidly shortlisting a set of already available vaccines that could be effective against the coronavirus.
Another interesting application of AI can be found in the selection of the right candidates, i.e. most likely to test positive for testing coronavirus in case of insufficient testing resources. This method was first exercised on Greek borders and was called project EVA. Whenever a traveler wanted to come into Greece, he had to fill out a form known as Passenger Locator Form (PLF) at least 24 hours prior to arrival, containing information on their origin country, demographics, point, and date of entry, and the intended destination. EVA then allocated testing resources according to the size of the set of passengers to be tested. After the test results, if found positive, they are put in quarantine. The results were sent back to the program for real-time learning.
The question remains how EVA made allocations, It was found that, statistically, only the origin country and the city were significant factors for screening. Ultimately, from a variety of countries and city pairs, EVA had to predict how many testing resources were to be allocated at each entry point and to particular passengers from a location is technically called the Multi-Armed Bandit (MAB) problem, and the chosen method to solve this problem was an AI algorithm called optimistic Gittins index. This algorithm identified on average 1.85x as many asymptomatic, infected travelers as random surveillance testing, and up to 2-4x as many during peak travel. After the test results, if found positive, they are put in quarantine. Following the collection of significant data through the aforementioned process, after a certain period, policies were made categorizing them separately and imposing restrictions on travelers from the specific location. This EVA as presented above was in operation from August 6th to November 1st processing around 38,500 PLFs each day and testing on an average 18.5% of households entering the country every day.
Above mentioned applications just show the tip of the iceberg and there is more to get into some of the other developments to watch for include the use of Image Recognition to identify covid based on x-ray images, the use of Deep Learning to predict the 3-D protein structure associated with COVID-19 and so on.
We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.
Contact us: hello@blackcoffer.com
© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd
